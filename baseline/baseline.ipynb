{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEVER: Fact Extraction and VERification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import fever\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalities of Oracle Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = '../data/fever/fever.db'\n",
    "MAT_PATH = 'data/index/tfidf-count-ngram=2-hash=16777216.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = fever.Oracle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Tetris has sold millions of physical copies.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tetris',\n",
       " 'Jolin_Tsai_discography',\n",
       " 'List_of_best-selling_Game_Boy_video_games',\n",
       " 'Eminem_discography']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.closest_docs(query, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Tetris -LRB- , pronounced -LSB- ˈtɛtrʲɪs -RSB- -RRB- is a tile-matching puzzle video game , originally designed and programmed by Russian game designer Alexey Pajitnov . It was released on June 6 , 1984 , while he was working for the Dorodnitsyn Computing Centre of the Academy of Science of the USSR in Moscow . He derived its name from the Greek numerical prefix tetra - -LRB- all of the game 's pieces contain four segments -RRB- and tennis , Pajitnov 's favorite sport .   Tetris was the first entertainment software to be exported from the USSR to the US , where it was published by Spectrum HoloByte for Commodore 64 and IBM PC . The Tetris game is a popular use of tetrominoes , the four-element special case of polyominoes . Polyominoes have been used in popular puzzles since at least 1907 , and the name was given by the mathematician Solomon W. Golomb in 1953 . However , even the enumeration of pentominoes is dated to antiquity .   The game -LRB- or one of its many variants -RRB- is available for nearly every video game console and computer operating system , as well as on devices such as graphing calculators , mobile phones , portable media players , PDAs , Network music players and even as an Easter egg on non-media products like oscilloscopes . It has even inspired Tetris serving dishes and been played on the sides of various buildings .   While versions of Tetris were sold for a range of 1980s home computer platforms as well as arcades , it was the hugely successful handheld version for the Game Boy launched in 1989 that established the game as one of the most popular ever . Electronic Gaming Monthly '' 's 100th issue had Tetris in first place as `` Greatest Game of All Time '' . In 2007 , Tetris came in second place in IGN 's `` 100 Greatest Video Games of All Time '' . In January 2010 , it was announced that the Tetris franchise had sold more than 170 million copies , approximately 70 million physical copies and over 100 million copies for cell phones , making it the best selling paid-downloaded game of all time . On 14 March 2014 , The Tetris Company announced a deal to bring Tetris '' to two of the latest hardware platforms , the Xbox One and PlayStation 4 , in partnership with Ubisoft -LRB- publishing -RRB- and SoMa Play -LRB- development -RRB- , to coincide with the franchise 's 30th anniversary . \"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.doc_ids2texts(['Tetris'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tetris -LRB- , pronounced -LSB- ˈtɛtrʲɪs -RSB- -RRB- is a tile-matching puzzle video game , originally designed and programmed by Russian game designer Alexey Pajitnov .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.get_sentence('Tetris', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Tetris',\n",
       "  12): 'In January 2010 , it was announced that the Tetris franchise had sold more than 170 million copies , approximately 70 million physical copies and over 100 million copies for cell phones , making it the best selling paid-downloaded game of all time .',\n",
       " ('Jolin_Tsai_discography',\n",
       "  9): 'Her next release under Sony , Magic -LRB- 2003 -RRB- , was heralded as her comeback album , which sold more than 1.5 million copies in Asia , with more than 360,000 copies sold in Taiwan alone , and the album made her the best-selling female singer of the year in Taiwan .',\n",
       " ('Jolin_Tsai_discography',\n",
       "  11): 'The album has sold over 2 million copies in Asia , with 300,000 copies sold in Taiwan alone , and made her the best-selling female singer of the year in Taiwan .'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.choose_sents_from_doc_ids(query, oracle.closest_docs(query, k=4), k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Tetris',\n",
       "  12): 'In January 2010 , it was announced that the Tetris franchise had sold more than 170 million copies , approximately 70 million physical copies and over 100 million copies for cell phones , making it the best selling paid-downloaded game of all time .',\n",
       " ('Jolin_Tsai_discography',\n",
       "  9): 'Her next release under Sony , Magic -LRB- 2003 -RRB- , was heralded as her comeback album , which sold more than 1.5 million copies in Asia , with more than 360,000 copies sold in Taiwan alone , and the album made her the best-selling female singer of the year in Taiwan .',\n",
       " ('Jolin_Tsai_discography',\n",
       "  11): 'The album has sold over 2 million copies in Asia , with 300,000 copies sold in Taiwan alone , and made her the best-selling female singer of the year in Taiwan .'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.read(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fever_iterator = iter(fever.TrainReader().read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fever_ex = next(fever_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\n",
      "VERIFIABLE\n",
      "SUPPORTS\n"
     ]
    }
   ],
   "source": [
    "print(fever_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FEVER Example({'id': 75397, 'verifiable': 'VERIFIABLE', 'label': 'SUPPORTS', 'claim': 'Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.', 'evidence': [[[92206, 104971, 'Nikolaj_Coster-Waldau', 7], [92206, 104971, 'Fox_Broadcasting_Company', 0]]]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fever_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Nikolaj_Coster-Waldau', 7), ('Fox_Broadcasting_Company', 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fever_ex.get_evidence_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fever_labels = pd.Series(\n",
    "    [ex.label for ex in fever.TrainReader().read()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUPPORTS           80035\n",
       "NOT ENOUGH INFO    35639\n",
       "REFUTES            29775\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fever_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fever_labels = pd.Series(\n",
    "    [ex.label for ex in fever.DevReader().read()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUPPORTS           3333\n",
       "NOT ENOUGH INFO    3333\n",
       "REFUTES            3333\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fever_labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Document Retrieval and Sentence Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 7243examples [12:17,  9.83examples/s]                    \n",
      "Reading from dataset:   0%|          | 0/7199 [00:00<?, ?examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_docs = 1, accuracy 1265/5455 = 0.23189734188817598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 7248examples [12:01, 10.04examples/s]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_docs = 3, accuracy 2503/5454 = 0.45892922625595894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset:  98%|█████████▊| 7239/7388 [11:55<00:16,  9.06examples/s]\n",
      "Reading from dataset:   0%|          | 0/7129 [00:00<?, ?examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_docs = 5, accuracy 3059/5461 = 0.5601538179820545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 7388examples [11:58,  7.98examples/s]                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_docs = 10, accuracy 3824/5618 = 0.6806692773228907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "for num_docs in [1,3,5,10]:\n",
    "    fever.doc_retrieval_accuracy(reader=fever.TrainReader(samp_percentage=0.05),\n",
    "                                oracle=oracle,\n",
    "                                num_docs=num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 7423examples [02:54, 44.67examples/s]                    \n",
      "Reading from dataset:   0%|          | 4/7388 [00:00<03:24, 36.05examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_sents = 1, accuracy 2870/5602 = 0.5123170296322742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset:  99%|█████████▉| 7306/7388 [02:44<00:01, 44.36examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_sents = 3, accuracy 3657/5537 = 0.660465956294022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset:  98%|█████████▊| 7181/7328 [02:40<00:03, 44.84examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_sents = 5, accuracy 3935/5398 = 0.7289736939607262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset:  98%|█████████▊| 7177/7354 [02:38<00:03, 45.30examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_sents = 10, accuracy 4367/5356 = 0.8153472740851382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for num_sents in [1,3,5,10]:\n",
    "    fever.sentence_selection_accuracy(reader=fever.TrainReader(samp_percentage=0.05),\n",
    "                                oracle=oracle,\n",
    "                                num_sents=num_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling for NotEnoughInfo class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_for_NEI(oracle, num_docs=5, num_sents=5):\n",
    "    names = ['train','dev','test']\n",
    "    for name in names:\n",
    "        print('Working on {} split'.format(name))\n",
    "        original_path = 'data/fever-data/{}.jsonl'.format(name)\n",
    "        sampling_path = 'data/fever-data/{}_sampled.jsonl'.format(name)\n",
    "        with open(original_path, \"r\") as f:\n",
    "            with open(sampling_path, \"w+\") as f2:\n",
    "                for line in tqdm(f.readlines()):\n",
    "                    line = json.loads(line)\n",
    "\n",
    "                    if name == 'dev' or name == 'test' or line[\"label\"] == \"NOT ENOUGH INFO\":\n",
    "                        evidences = oracle.read(line['claim'], num_docs=num_docs, num_sents=num_sents).keys()\n",
    "                        line['evidence'] = [[[0,0,ev[0],ev[1]] for ev in evidences]]\n",
    "\n",
    "                    f2.write(json.dumps(line) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/145449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on train split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145449/145449 [3:01:26<00:00, 13.36it/s]  \n",
      "  0%|          | 0/9999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dev split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [51:59<00:00,  3.26it/s]  \n",
      "  0%|          | 1/9999 [00:00<25:34,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [51:48<00:00,  4.85it/s]  \n"
     ]
    }
   ],
   "source": [
    "sampling_for_NEI(oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RTE Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_overlap_phi(claim, evidence):    \n",
    "    \"\"\"Basis for features for the words in both the premise and hypothesis.\n",
    "    This tends to produce very sparse representations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    claim : a string\n",
    "    evidence : a list of sentences\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    defaultdict\n",
    "       Maps each word in both claim and evidence to 1.\n",
    "    \n",
    "    \"\"\"\n",
    "    sents=[]\n",
    "    for sent in evidence:\n",
    "        sents.extend(utils.process_sent(sent))\n",
    "    overlap = set([w1 for w1 in utils.process_text(claim) if w1 in sents])\n",
    "    return Counter(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_maxent_classifier(X, y):    \n",
    "    \"\"\"Wrapper for `sklearn.linear.model.LogisticRegression`. This is also \n",
    "    called a Maximum Entropy (MaxEnt) Classifier, which is more fitting \n",
    "    for the multiclass case.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2d np.array\n",
    "        The matrix of features, one example per row.\n",
    "    y : list\n",
    "        The list of labels for rows in `X`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sklearn.linear.model.LogisticRegression\n",
    "        A trained `LogisticRegression` instance.\n",
    "    \n",
    "    \"\"\"\n",
    "    mod = LogisticRegression(fit_intercept=True)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 14441examples [02:04, 115.78examples/s]                     \n"
     ]
    }
   ],
   "source": [
    "dataset = fever.build_dataset(fever.SampledTrainReader(samp_percentage=percentage), \n",
    "                              word_overlap_phi, oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 14781examples [02:04, 118.96examples/s]                     \n",
      "Reading from dataset: 100%|██████████| 9999/9999 [04:57<00:00, 33.66examples/s]\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT ENOUGH INFO      0.363     0.222     0.275      3333\n",
      "        REFUTES      0.353     0.038     0.069      3333\n",
      "       SUPPORTS      0.333     0.758     0.463      3333\n",
      "\n",
      "       accuracy                          0.340      9999\n",
      "      macro avg      0.349     0.340     0.269      9999\n",
      "   weighted avg      0.349     0.340     0.269      9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = fever.experiment(\n",
    "    train_reader=fever.SampledTrainReader(samp_percentage=percentage), \n",
    "    phi=word_overlap_phi,\n",
    "    oracle=oracle,\n",
    "    train_func=fit_maxent_classifier,\n",
    "    assess_reader=fever.SampledDevReader(),\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cross_product_phi(claim, evidence):\n",
    "    \"\"\"Basis for cross-product features. This tends to produce pretty \n",
    "    dense representations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    claim : a string\n",
    "    evidence : a list of sentences\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    defaultdict\n",
    "        Maps each (w1, w2) in the cross-product of words in claim and \n",
    "        evidence to its count. This is a multi-set cross-product\n",
    "        (repetitions matter).\n",
    "    \n",
    "    \"\"\"\n",
    "    sents=[]\n",
    "    for sent in evidence:\n",
    "        sents.extend(utils.process_sent(sent))\n",
    "    return Counter([(w1, w2) for w1, w2 in product(utils.process_text(claim), sents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 14713examples [02:14, 109.66examples/s]                     \n",
      "Reading from dataset: 100%|██████████| 9999/9999 [05:17<00:00, 31.52examples/s]\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT ENOUGH INFO      0.361     0.402     0.381      3333\n",
      "        REFUTES      0.556     0.233     0.328      3333\n",
      "       SUPPORTS      0.372     0.547     0.443      3333\n",
      "\n",
      "       accuracy                          0.394      9999\n",
      "      macro avg      0.430     0.394     0.384      9999\n",
      "   weighted avg      0.430     0.394     0.384      9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = fever.experiment(\n",
    "    train_reader=fever.SampledTrainReader(samp_percentage=percentage), \n",
    "    phi=word_cross_product_phi,\n",
    "    oracle=oracle,\n",
    "    train_func=fit_maxent_classifier,\n",
    "    assess_reader=fever.SampledDevReader(),\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_maxent_with_crossvalidation(X, y):\n",
    "    \"\"\"A MaxEnt model of dataset with hyperparameter cross-validation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2d np.array\n",
    "        The matrix of features, one example per row.\n",
    "        \n",
    "    y : list\n",
    "        The list of labels for rows in `X`.   \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sklearn.linear_model.LogisticRegression\n",
    "        A trained model instance, the best model found.\n",
    "    \n",
    "    \"\"\"    \n",
    "    basemod = LogisticRegression(fit_intercept=True)\n",
    "    cv = 3\n",
    "    param_grid = {'C': [0.4, 0.6, 0.8, 1.0],\n",
    "                  'penalty': ['l1','l2']}    \n",
    "    return fever.fit_classifier_with_crossvalidation(X, y, basemod, cv, param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 100%|██████████| 145449/145449 [20:28<00:00, 118.42examples/s]\n",
      "Reading from dataset: 100%|██████████| 9999/9999 [04:55<00:00, 33.85examples/s]\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 1.0, 'penalty': 'l2'}\n",
      "Best score: 0.430\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT ENOUGH INFO      0.362     0.329     0.344      3333\n",
      "        REFUTES      0.424     0.012     0.023      3333\n",
      "       SUPPORTS      0.337     0.696     0.454      3333\n",
      "\n",
      "       accuracy                          0.346      9999\n",
      "      macro avg      0.374     0.346     0.274      9999\n",
      "   weighted avg      0.374     0.346     0.274      9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unigram+bigram result\n",
    "_ = fever.experiment(\n",
    "    train_reader=fever.SampledTrainReader(), \n",
    "    phi=word_overlap_phi,\n",
    "    oracle=oracle,\n",
    "    train_func=fit_maxent_with_crossvalidation,\n",
    "    assess_reader=fever.SampledDevReader())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 100%|██████████| 145449/145449 [20:23<00:00, 118.89examples/s]\n",
      "Reading from dataset: 100%|██████████| 9999/9999 [04:57<00:00, 33.59examples/s]\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 1.0, 'penalty': 'l2'}\n",
      "Best score: 0.430\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT ENOUGH INFO      0.362     0.326     0.343      3333\n",
      "        REFUTES      0.418     0.011     0.022      3333\n",
      "       SUPPORTS      0.337     0.698     0.454      3333\n",
      "\n",
      "       accuracy                          0.345      9999\n",
      "      macro avg      0.372     0.345     0.273      9999\n",
      "   weighted avg      0.372     0.345     0.273      9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unigram test result\n",
    "_ = fever.experiment(\n",
    "    train_reader=fever.SampledTrainReader(), \n",
    "    phi=word_overlap_phi,\n",
    "    oracle=oracle,\n",
    "    train_func=fit_maxent_with_crossvalidation,\n",
    "    assess_reader=fever.SampledDevReader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from dataset: 28999examples [04:05, 118.24examples/s]                     \n",
      "Reading from dataset: 100%|██████████| 9999/9999 [05:17<00:00, 31.52examples/s]\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 1.0, 'penalty': 'l1'}\n",
      "Best score: 0.602\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT ENOUGH INFO      0.356     0.515     0.421      3333\n",
      "        REFUTES      0.546     0.233     0.327      3333\n",
      "       SUPPORTS      0.382     0.429     0.404      3333\n",
      "\n",
      "       accuracy                          0.392      9999\n",
      "      macro avg      0.428     0.392     0.384      9999\n",
      "   weighted avg      0.428     0.392     0.384      9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = fever.experiment(\n",
    "    train_reader=fever.SampledTrainReader(samp_percentage=percentage), \n",
    "    phi=word_cross_product_phi,\n",
    "    oracle=oracle,\n",
    "    train_func=fit_maxent_with_crossvalidation,\n",
    "    assess_reader=fever.SampledDevReader(),\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "_merged"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
