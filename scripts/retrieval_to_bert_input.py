import json
import sqlite3
from tqdm import tqdm
from drqa.retriever import utils
ENCODING = 'utf-8'
DATABASE = '../data/fever/fever.db'

conn = sqlite3.connect(DATABASE)
cursor = conn.cursor()

'''
    Build train/dev/test set from retrieval results for BERT.
'''
def process(input, output):
    fin = open(input, 'rb')
    instances = []
    index = 0
    file_name = input.split('/') [-1]
    if file_name == 'train.ensembles.s10.jsonl':
        splits = 15000
    elif file_name == 'dev.ensembles.s10.jsonl':
        splits = 15000
    elif file_name == 'test.ensembles.s10.jsonl':
        splits = 5000

    for line in fin:
        if index == splits:
            break
        object = json.loads(line.decode(ENCODING).strip('\r\n'))
        if 'label' in object:
            label = ''.join(object['label'].split(' '))
        else:
            label = 'REFUTES'
        evidences = object['predicted_evidence']
        claim = object['claim']
        instances.append([index, label, claim, evidences])
        index += 1
    fin.close()
    print(index)

    fout = open(output, 'wb')
    for instance in tqdm(instances):
        index, label, claim, evidences = instance
        for evidence in evidences:
            article = evidence[0]
            location = evidence[1]
            evidence_str = None
            cursor.execute(
                "SELECT * FROM documents WHERE id = ?",
                (utils.normalize(article),)
            )
            for row in cursor:
                sentences = row[2].split('\n')
                for sentence in sentences:
                    if sentence == '': continue
                    arr = sentence.split('\t')
                    if not arr[0].isdigit():
                        # print(('Warning: this line from article %s for claim %d is not digit %s\r\n' % (article, i, sentence)).encode(ENCODING))
                        continue
                    line_num = int(arr[0])
                    if len(arr) <= 1: continue
                    sentence = ' '.join(arr[1:])
                    if sentence == '':
                        continue
                    if line_num == location:
                        evidence_str = sentence
                        break
            if evidence_str:
                fout.write(('%s\t%s\t%s\t%s\t%s\t%d\t%s\r\n' % (label, evidence_str, claim, index, evidence[0], evidence[1], evidence[2])).encode(ENCODING))
            else:
                print('Error: cant find %s %d for %s' % (article, location, index))
    fout.close()


'''
    Build support/refute samples of train dataset for BERT.
'''
def build_bert_train_sr_set(data_dir, output_dir):
    # fin = open(data_dir, 'rb')
    # fout = open(output_dir, 'wb')
    cnt = -1
    with open(data_dir, 'rb') as fin, open(output_dir, 'wb') as fout:
        for line in fin:
            cnt += 1
            if cnt == 15000:
                print(cnt)
                break

            data = json.loads(line)
            claim = data['claim']
            evidences = data['evidence']
            label = data['label']

            if label == 'NOT ENOUGH INFO':
                continue

            for evidence_set in evidences:
                # text_set = []
                for evidence in evidence_set:
                    article = evidence[2]
                    article_index = evidence[3]
                    try:
                        cursor.execute("select * from documents where id='%s';" % article.replace("'", "''"))
                    except Exception as e:
                        print(e)
                        continue
                    for row in cursor:
                        lines = row[2].split('\n')
                        items = lines[article_index].split('\t')

                        sentence = ' '.join(items[1:])

                        fout.write(('%s\t%s\t%s\t%d\t%s\t%s\r\n' % (label, sentence, claim, cnt, article, article_index)).encode(ENCODING))

    # fin.close()
    # fout.close()


if __name__ == '__main__':
    build_bert_train_sr_set('../data/fever/train.jsonl', '../data/bert/bert-nli-train-sr-set.tsv')
    process('../data/retrieved/train.ensembles.s10.jsonl', '../data/bert/bert-nli-train-retrieve-set.tsv')
    process('../data/retrieved/dev.ensembles.s10.jsonl', '../data/bert/bert-nli-dev-retrieve-set.tsv')
    process('../data/retrieved/test.ensembles.s10.jsonl', '../data/bert/bert-nli-test-retrieve-set.tsv')
